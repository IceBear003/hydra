# Hydra小队 全技术细节

## **高速多端口共享缓存管理模块**

### 基本概念

SRAM参数：32块，位宽16，深度16384

端口参数：wr_data和rd_data位宽均为16，其他接口位宽均为1

半字（half word）：16bits，即2bytes

页（page）：8半字，即128bits，16bytes

物理地址（phsical address）：与SRAM交互时直接使用的地址，可以认为每个物理地址可在SRAM中访问到一个半字的信息。由于SRAM的深度为16384，故对于一个SRAM来说，物理地址为14位，又由于共有32块SRAM，故相对于外界而言，物理地址为5+14位，描述了哪一块SRAM的哪一个半字。

线性地址（linear address）：与SRAM交互时间接使用的地址，一个线性地址可生成八个物理地址，映射关系成线性。可以认为每个线性地址对应一页。由于SRAM共有2048页，对于一个SRAM来说，线性地址为11位，又由于共有32块SRAM，故相对于外界而言，线性地址有5+11位，描述了哪一块SRAM的哪一页。

### 数据包

#### 包参数

由题干可知，一个数据包长度为64~1024字节，合32~512半字/4~64页。

#### 包格式

数据包由控制和数据部分组成，现拟定控制部分长16位，由9位长度、3位优先级、4位目的端口号组成。其中9位长度为数据包有多少半字（与512相对应）。

#### 存储形式

SRAM分配空间时以页为单位，即对于N字节的数据包，其占用的空间为⌈N/16⌉，即最后一页可能只有一部分有数据。同一个数据包分配的页不一定全部连续。

存入1页需要写入8半字，因此也就需要8个周期。当数据源源不断地从端口每半字地写入，每半字都在1个周期后立刻写入SRAM（此机制将在时序章节中详细说明）。

存储在SRAM里时，数据包仍然具有控制部分，但与从端口写入时略有区别。此时第一个半字并非9+3+4的形式，而是(2+)6+(5+)3的形式，其中6位数字X表示数据包占X+1页（与数据包最多64页对应），3位数字Y表示数据包的最后一页有Y+1半字（与1页有8半字对应）。可以注意到，这里的X和Y实际上就是原来的9位长度从中间拆分开直接得到。

#### 纠错策略

本模块使用传统的ECC汉明校验，每1页数据生成8位校验码。运算校验码时采用了异或树的结构，大大缩短了运算时间（从127次串行运算变为7次串并行运算）。

校验码存储在SRAM外部，每个SRAM都包含一个长度为2048的8位数字数组，分别对应SRAM中每一页的纠错信息，因此任意一页的纠错码存储位置可直接通过线性地址描述。

当1页的数据写入完毕时，校验码将会生成并存储在对应的位置。当1页的数据读出时，校验码将会被取出并参与SEC过程，可以注意到，对于1页中第1半字的数据，需要等到第8半字的数据取出才能被纠错，这会导致读数据滞后7个周期，本模块采用了预读取的策略，消除了该滞后（此机制将在时序章节中详细说明）。

#### 内存回收

为了实现内存自动申请、回收的功能，本模块使用了空闲队列，一个类FIFO(first in, first out)的数据结构，描述了SRAM中哪些页是空闲的。由此可知，每一个SRAM都绑定一个空闲队列。

空闲队列本质上是一个宽度为11，深度为2048的FIFO。每一个11位的元素都是一个线性地址，指向了SRAM中空闲的一页。当新一页的数据写入SRAM时，将会直接使用从空闲队列头弹出元素的线性地址，生成物理地址完成写操作；当读出一页数据时，意味着数据原本占用的页重新回到了空闲状态，该页的地址将会被推入队尾，等待后续被弹出重新利用。这样就完成了时间复杂度为O(1)的内存分配、回收机制。

//目前空间占用可怕，FIFO 2048*11bits≈3KB 管理 32KB 分配

//决赛阶段实现组合逻辑算法，压缩空闲队列占用，解决内存碎片化问题

### 端口

#### 分配策略

当外界向一个端口写入新的数据包时，由于wr_data位宽为16，因此数据包的大小一定是16bits的整数倍。上文提到一个数据包占32~512半字，或4~64页，其中第一半字对应数据包的控制部分，当第一半字刚读入时，可知道当前数据包的去向（目的端口dest_port和优先级priority），此时立即寻找一个SRAM与该数据包绑定，用于存储包的所有信息，寻找的策略如下（软性要求从上至下优先度降低）：

硬性要求，必须满足：

1）SRAM当前未与其他数据包绑定；

> SRAM同时只能进行一次读写

2）SRAM剩余的空间足以完全容纳下当前数据包；

> 本模块设计下一个数据包必须全在一个SRAM中，不得拆分开来存储于不同SRAM中
> 这样有助于简化组合逻辑，并降低读取延迟（见时序章节的详细说明）

3）SRAM中目的端口的数据包占用小于75%；

> 为其他端口预留一定空间，防止极端情况下，所有SRAM全被一个端口占用，其他端口根本无法写入数据

软性要求，从上向下，一旦发现满足条件的即停止：

1）与目的端口对应优先级的队列的尾地址在同一SRAM中；

> 通过维持端口数据包的聚合度，降低因为竞争导致的读取延迟

2）SRAM中端口数量较少；

> 通过降低每个SRAM中端口个数，降低因为竞争导致的读取延迟

3）满足硬性要求的SRAM。

> 最后的底牌，实在没办法了就随便抓一个可用的咯

#### 优先级队列

传统方案：

1）使用FIFO存储每个端口每个优先级的数据包存放地址

> 弊端：难以确定FIFO的深度。如果按最保守计算，考虑最极端的情况，即所有数据包涌入仅一个端口一个优先级，那么FIFO至少深16384，这样的FIFO有16*8=128个，数据量极为可怕，甚至大于SRAM本身；如果稍小一点，则有可能出现FIFO爆满，不足以容纳新进入的数据包的地址信息，即使在FIFO满的时候拉高FULL阻止输入，也会导致内存无法完全地被动态分配（FIFO满之后，即使SRAM还有空间，也无法写入新数据包）

2）将每个优先级的队列以链表的形式存储，数据包为结点，结点的控制信息（一般是下一个结点的地址）与结点本身一并存储在SRAM里

> 优势：避免了巨型FIFO
>
> 弊端：极大增加了时序复杂性，写入数据时要提前为下一批数据预分配，需要额外避免预分配竞争的问题；会使得数据包在SRAM中无法与页对齐（即最小的数据包需要5页，最后1页只记录了一些数据，大部分被浪费），与页表管理设计不匹配，浪费资源。

本模块的方案：为每个SRAM设置一张跳转表，其本质上类似于将链表中结点指向下一结点的控制信息剥离出来。跳转表是一个16位宽，2048位长度的数组，每个元素对应了SRAM中的一页，16位宽代表一个线性地址，表述对应页的下一页的地址，这样，我们就可以把无论相邻与否，是否在同一SRAM中的页串起来，成一个链，对应一个端口的一个优先级。对于一个优先级来说，只需要维护其头尾的指针，就可以维护这个链（只能访问修改头尾的链表不就是队列嘛）

> 优势：避免了巨型FIFO；通过外存地址，极大简化了时序复杂性，无需实现预分配操作；同时跳转表的大小明确，占用空间可以接受。

当新来一个数据包，一页一页按顺序写入，分配的地址只需不断写入链尾页对应的跳转表位置，并更新尾部指针即可。

当读出一个数据包，从头部指针访问并读出页，之后将头部指针设置为原头部对应的跳转地址即可。

#### 调度模式

本模块支持严格优先级调度、WRR调度。

严格优先级调度遵循优先级至上的原则，同一个端口读出时总是先安排高优先级的队列的读取，直到其为空，再考虑较低优先级的队列的读取。

WRR调度则在遵循优先级的同时，为低优先级的队列考虑，即缓解低优先级永远被高优先级队列堵住的问题。目前采用的是线性加权，即队列的读取权重等于其优先度，比如优先度为5的队列每读出5个单位的数据，优先度为4的队列读出4个单位的数据。

### 时序细节



### 亮点



### 缺点



